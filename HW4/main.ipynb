{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hashing task!\n",
    "In this first task we are implementing hash functions and a structure called Bloom Filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random as rnd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bloom filter class will have two ins_functions. \n",
    "# The first will contain the array representing the bloom filter,\n",
    "# the second is a list of hash functions which witance attributes:\n",
    "# Bloom_Filter.array and Bloom_Filter.hashll be used to insert and search elements on the data structure.\n",
    "class Bloom_Filter:\n",
    "    \n",
    "    \n",
    "    def __init__(self, size, hash_functions):\n",
    "        self._array = np.empty(size, dtype = bool)\n",
    "        self._hash_functions = hash_functions\n",
    "    \n",
    "   \n",
    "    def insert(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            self._array[function(element)] = True\n",
    "            \n",
    "    def check(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            if(not self._array[function(element)]):\n",
    "                return(False)\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n"
     ]
    }
   ],
   "source": [
    "# #We know the folllowing approximate formula to get a reasonable value of m given an error tolerance p as well as the size n of the elements we are going to insert on the set\n",
    "#     m = -\\frac{n \\ln{p}}{(\\ln{2})^{2}}\n",
    "\n",
    "# For the error tolerance $p$ we are going t choose the value $0.01$ so that we'll have only a 1\\% rate of false positives.\n",
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "counter = 0\n",
    "while(passwords.readline()):\n",
    "    counter = counter + 1\n",
    "passwords.close()\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found out thar our list consists of 100 milions passwords. \n",
    "\n",
    "Knowing this we can finally compute m with the formula given above and get\n",
    "\n",
    "m =958505838\n",
    "\n",
    "k = \\frac{m}{n}\\ln{2}\n",
    "\n",
    "k = 6.64\n",
    "\n",
    "So we're going to use seven hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 !\n",
      "122 z\n"
     ]
    }
   ],
   "source": [
    "# We're going to save the minimum as well the maximum possible character in our file\n",
    "#(characters are ordered by their ASCII code)\n",
    "\n",
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "\n",
    "minimum = 102\n",
    "maximum = 102\n",
    "\n",
    "\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]: \n",
    "        if(ord(character) < minimum):\n",
    "            minimum = ord(character)\n",
    "        if(ord(character) > maximum):\n",
    "            maximum = ord(character)\n",
    "\n",
    "print(minimum, chr(minimum))\n",
    "print(maximum, chr(maximum))\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that every password can contain characters ranging from \"!\" to \"z\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "\n",
    "counter = [0] * (122 - 33 + 1)\n",
    "\n",
    "\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]:\n",
    "        counter[ord(character) - 33] += 1\n",
    "\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226536,\n",
       " 226375,\n",
       " 226357,\n",
       " 226105,\n",
       " 226044,\n",
       " 226000,\n",
       " 226268,\n",
       " 226404,\n",
       " 225767,\n",
       " 225890,\n",
       " 225885,\n",
       " 226388,\n",
       " 226831,\n",
       " 225541,\n",
       " 225986,\n",
       " 226636,\n",
       " 225616,\n",
       " 227077,\n",
       " 226304,\n",
       " 227385,\n",
       " 226377,\n",
       " 225768,\n",
       " 226336,\n",
       " 226474,\n",
       " 226330,\n",
       " 226024,\n",
       " 226416,\n",
       " 226617,\n",
       " 226811,\n",
       " 226216,\n",
       " 226053,\n",
       " 226097,\n",
       " 225798,\n",
       " 226659,\n",
       " 225852,\n",
       " 226279,\n",
       " 226296,\n",
       " 226135,\n",
       " 226755,\n",
       " 226109,\n",
       " 226002,\n",
       " 225869,\n",
       " 226628,\n",
       " 225940,\n",
       " 226091,\n",
       " 226075,\n",
       " 225593,\n",
       " 225928,\n",
       " 225867,\n",
       " 226701,\n",
       " 225958,\n",
       " 226349,\n",
       " 226193,\n",
       " 226762,\n",
       " 225935,\n",
       " 226347,\n",
       " 226287,\n",
       " 226075,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 226032,\n",
       " 225611,\n",
       " 226913,\n",
       " 226309,\n",
       " 225951,\n",
       " 226027,\n",
       " 225492,\n",
       " 226486,\n",
       " 225835,\n",
       " 225963,\n",
       " 226979,\n",
       " 226746,\n",
       " 225956,\n",
       " 226440,\n",
       " 226128,\n",
       " 225894,\n",
       " 225349,\n",
       " 225799,\n",
       " 226374,\n",
       " 226345,\n",
       " 225788,\n",
       " 225929,\n",
       " 225759,\n",
       " 225880,\n",
       " 226971,\n",
       " 225647]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every password in the file is a randome string where every character is independently drawn in the set of characters whose ASCII code ranges from 33 to 122, excluding those one whose code ranges from 91 to 96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_10(character):\n",
    "    value = ord(character)\n",
    "    \n",
    "    \n",
    "    if(value < 91):\n",
    "        return(value - 33)\n",
    "    else:\n",
    "        return(value - 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We remember that values ranging from 91 to 96 do not appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_1(string):\n",
    "    value  = 0\n",
    "    for index in range(len(string) - 1, -1, -1):\n",
    "        value = (84 * value + get_base_10(string[index])) % 958505838\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_string(string, step):\n",
    "    return(string[step:] + string[:step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our other six functions and since they will be all similar we're going to define an high order function which will take as parameters one hash function (in our case hash_1) and a number $k$ and will return our $k$-th hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(first_hash_function, k):\n",
    "    \n",
    "   \n",
    "    return(lambda x : hash_1(rotate_string(x, k - 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're going to inizialize our Bloom_Filter class save our hash functions in a list after that we can pass it as a parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_functions = [hash_function(hash_1, index + 1) for index in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function returns the number of strings from the second data set that are possibly contained in the first data set\n",
    "# and the execution time for finding this number\n",
    "def task(first_data_set, second_data_set, m, hash_functions):\n",
    "    \n",
    "   \n",
    "    bloom_filter = Bloom_Filter(m, hash_functions)\n",
    "    \n",
    "    \n",
    "    strings = open(first_data_set, \"r\")\n",
    "    start = time.time()\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1] \n",
    "        bloom_filter.insert(string)\n",
    "    strings.close()\n",
    "    \n",
    "# This can check how many strings from the second data set are probably on the first data set  \n",
    "# Possible duplicates containing list also created\n",
    "    strings = open(second_data_set, \"r\")\n",
    "    possible_dups = []\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1]\n",
    "        if(bloom_filter.check(string)):\n",
    "            possible_dups.append(string)\n",
    "    end = time.time()\n",
    "    strings.close()\n",
    "    \n",
    "    return((possible_dups, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hash functions used:  7\n",
      "Number of possibly duplicates:  14261334\n",
      "Probability of false positives: 0.01\n",
      "Execution time:  6857.633438587189\n"
     ]
    }
   ],
   "source": [
    "if(not os.path.isfile(\"possible_dups.txt\")):\n",
    "    result = task(\"passwords1.txt\", \"passwords2.txt\", 958505838, hash_functions)\n",
    "    f = open(\"possible_dups.txt\", \"w\")\n",
    "    f.write(str(result[1]) + \"\\n\")\n",
    "    for password in result[0]:\n",
    "        f.write(password + \"\\n\")\n",
    "    f.close()\n",
    "else:\n",
    "    f = open(\"possible_dups.txt\", \"r\")\n",
    "    result = [[], 0]\n",
    "    result[1] = float(f.readline())\n",
    "    while(True):\n",
    "        string = f.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1]\n",
    "        result[0].append(string)\n",
    "    f.close()\n",
    "\n",
    "# We print the results\n",
    "print('Number of hash functions used: ', len(hash_functions))\n",
    "print('Number of possibly duplicates: ', len(result[0]))\n",
    "print('Probability of false positives: 0.01')\n",
    "print('Execution time: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS\n",
    "\n",
    "Assuming that our hash function behaves well (and we hope so based on our discussions in the previous sections) all this process should take an amount of time linear in the size n =100000000 of the first data set, which seems reasonable.\n",
    "\n",
    "So let's start by creating our array hash_duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_dictionary(list_of_data, hash_function):\n",
    "    to_return = defaultdict(list)\n",
    "    for element in list_of_data:\n",
    "        to_return[hash_function(element)].append(element)\n",
    "    return(to_return)\n",
    "#We now create our dictionary of possibly duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_dups_dict = hash_dictionary(result[0], hash_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of false positives: 261334\n"
     ]
    }
   ],
   "source": [
    "f = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "while(True):\n",
    "    string = f.readline()\n",
    "    if(string == \"\"):\n",
    "        break\n",
    "    string = string[:len(string) - 1]\n",
    "    hash_value = hash_1(string)\n",
    "    if(string in possible_dups_dict[hash_value]):\n",
    "        possible_dups_dict[hash_value].remove(string)\n",
    "\n",
    "f.close()\n",
    "\n",
    "false_positives = []\n",
    "for elements in possible_dups_dict.values():\n",
    "    false_positives.extend(elements)\n",
    "\n",
    "print(\"Number of false positives: \" + str(len(false_positives)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the percentage of false positives is approximately 1.8%. This is a bit more than 1% as we initially asked, probably due to the fact that, as we have seen, our hash functions can't be exactly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Alphabetical Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we wil focus on sorting characters and strings. \n",
    "### Part 1:\n",
    "For the first part we were asked to implement the Counting Sort algorithm and this is how we did it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def counting_sort(l):\n",
    "\n",
    "    range_el = max(l) + 1\n",
    "    occur = [0] * range_el\n",
    "    final = [0] * (len(l))\n",
    "\n",
    "    for i in range(len(l)):\n",
    "        occur[l[i]] += 1\n",
    "\n",
    "    for i in range(1, len(occur)):\n",
    "        occur[i] = occur[i - 1] + occur[i]\n",
    "\n",
    "    for e in l:\n",
    "        final[occur[e]-1] = e\n",
    "        occur[e] -= 1\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N.B.\n",
    "* range_el is the range of the elements we are trying to sort, basically it corresponds to the biggest value we have int the list that we need to sort. \n",
    "* in the first loop we are counting the occurrences of every element\n",
    "* in the second loop we are summing each element of the occur vector with his previous one\n",
    "* in the third loop we are actually creating the ordered list (final) based on the info in the occur list\n",
    "\n",
    "We used [this video][1] as reference to understand how the counting sort works.\n",
    "\n",
    "\n",
    "[1]: https://www.youtube.com/watch?v=7zuGmKfUt7s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2:\n",
    "Here we wrote an algorithm that uses Counting Sort to sort the letter of the alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_char(char_list):\n",
    "\n",
    "    to_sort_int = [(ord(x) - 97) for x in char_list]  # turning the characters into int from 0 to 25\n",
    "    result = counting_sort(to_sort_int)               # running the counting sort on them \n",
    "    result = [chr(x + 97) for x in result]            # turning the int back into char\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "to_sort = ['p', 'a', 'n', 'd', 'r', 'e', 'q', 'w', 't', 'y', 'u', 'i', 'o', 's', 'f', 'g', 'h', 'j', 'k', 'l', 'z', 'x',\n",
    "           'c', 'v', 'b', 'm', 'f']\n",
    "\n",
    "print(sort_char(to_sort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Complexity:\n",
    "Counting sort is great for sorting positive numbers in a given and realtivly small range because it takes linear time to compute. In fact we don't have nested for loops. Every loop is either looping over len(input) or the range (k) of possible values of the input. In fact the complexity is O(n+k) where n is the length of the input list and k is the range the possible values of the elements in the list.\n",
    "In our algorithm that works on characters we didn't add complexity because we are only turning into int every char (a loop over n), calling the counting sort and then turning the int back into char (loop over n). So the time complexity remains linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3:\n",
    "In this part we built an algorithm based on counting sort to sort strings alphabetically. We decided to convert the strings into numbers (turning any char into a two digit number) and sort them basing our algorithm on the radix sort, which recursively calls counting sort to sort numbers first by the most significant digit, then next one and so on until the least significant one. In this algorithm we used some **auxiliary functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to prepar the input for the main function\n",
    "\n",
    "def prep_input(list_strings):\n",
    "\n",
    "    m = len(max(list_strings, key=len))  # max length of a string in the list\n",
    "    out = []\n",
    "    list_strings = [x.lower() for x in list_strings]  # converting to lowercase\n",
    "\n",
    "    for word in list_strings:            # for every word we prepare the new numerical string\n",
    "        s = \"\"\n",
    "        for letter in word: \n",
    "            if letter == \" \":            # if the word has spaces in it we represent them with the code '01'\n",
    "                s += '01'  \n",
    "            else:\n",
    "                s += str(ord(letter)-86)  # al the other letters are converted into a number (from 11 to 36)\n",
    "        if len(word) < m:\n",
    "            s = s.ljust((len(word) + (m-len(word)))*2, '0')  # if a string is shorter than m we pad it with \n",
    "                                                             # zeros at the end to have them of the same length\n",
    "        out.append(s)\n",
    "\n",
    "    out = [int(x) for x in out]          # converting all the strings into int\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# This functions is used to convert the numbers back into words after we sorted them\n",
    "\n",
    "def prettify(ordered_list_int):\n",
    "    result = []\n",
    "    for num in ordered_list_int:\n",
    "        num = str(num)\n",
    "        stringa = \"\"                                 # for every number we create a string\n",
    "        for i in range(1,len(num), 2):               # we have a character every two digits\n",
    "            if (num[i-1])+str(num[i]) == \"00\":       # 00 gets ignored beacuse it was just padding\n",
    "                continue\n",
    "            elif (num[i-1])+str(num[i]) == \"01\":     # 01 mean a space inside the string\n",
    "                stringa += \" \"\n",
    "            else:\n",
    "                stringa += chr(int(str(num[i-1])+str(num[i]))+86)  # all the other numbers are \n",
    "                                                                   # turnet back into chars\n",
    "        result.append(stringa)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then we have the **main functions** of the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same structure of the counting sort above, but with a little change that\n",
    "# lets us consider only the current decimal position (expressed by digit) to sort the numbers.\n",
    "# Moreover this time we are modifying the list in place\n",
    "\n",
    "def counting_sort_snd(l, digit):\n",
    "\n",
    "    occur = [0] * 10\n",
    "    final = [0] * (len(l)+1)\n",
    "\n",
    "    for i in range(len(l)):\n",
    "        occur[(l[i] // digit) % 10] += 1\n",
    "\n",
    "    for i in range(1, len(occur)):\n",
    "        occur[i] = occur[i - 1] + occur[i]\n",
    "\n",
    "    for e in reversed(l):\n",
    "        final[occur[(e // digit) % 10] - 1] = e\n",
    "        occur[(e // digit) % 10] -= 1\n",
    "\n",
    "    for i in range(len(l)):\n",
    "        l[i] = final[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our version of the radix sort algorithm; it finds out the biggest number in the list to order\n",
    "# and then calls the counting sort on every decimal position/digit incrementig it every time.\n",
    "\n",
    "def radix_sort(l):\n",
    "\n",
    "    range_el = max(l)\n",
    "    digit = 1\n",
    "\n",
    "    while range_el / digit > 0:\n",
    "        counting_sort_snd(l, digit)\n",
    "        digit *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* and this is the final product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_algorithm(to_sort):\n",
    "\n",
    "    print(\"Input: \", to_sort)            # printing input\n",
    "    prepped_list = prep_input(to_sort)   # preparing input\n",
    "\n",
    "    radix_sort(prepped_list)             # ordering list\n",
    "    result = prettify(prepped_list)      # make the result readable\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see it at work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  ['good', 'bad', 'building', 'oak hill', 'zara', 'kiss', 'kissing', 'oak', 'crazy', 'wow']\n",
      "Result:  ['bad', 'building', 'crazy', 'good', 'kiss', 'kissing', 'oak', 'oak hill', 'wow', 'zara']\n"
     ]
    }
   ],
   "source": [
    "input_test = [\"good\", \"bad\", \"building\", \"oak hill\", \"zara\", \"kiss\", \"kissing\", \"oak\", \"crazy\", \"wow\"]\n",
    "\n",
    "print(\"Result: \", my_algorithm(input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time complexity:\n",
    "The auxiliary funtions both take almost a quadratic time to be executed beacuse they loop on every word of the list and then on every letter of the word (or every two letters). More precisely they take O(m* n) where m is the number of words and n the maximum lenght of the words. The counting sort is the same so it's still linear. The radix_sort is calling the counting sort for every digit of the number so the total amount of the radix sort is O(m* j) where m is still the number of elements to sort and j is the medium number of digits they have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find similar wines!\n",
    "The goal of this exercise is clustering wines by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "# Reading csv dataset as it does not have header, and separated by names\n",
    "wine = pd.read_csv(\"wine.data\", names = [\"Class\", \n",
    "                                         \"Alcohol\",\n",
    "                                         \"Malic acid\",\n",
    "                                         \"Ash\",\n",
    "                                         \"Alcalinity of ash\",\n",
    "                                         \"Magnesium\",\n",
    "                                         \"Total phenols\",\n",
    "                                         \"Flavanoids\",\n",
    "                                         \"Nonflavanoid phenols\",\n",
    "                                         \"Proanthocyanins\",\n",
    "                                         \"Color intensity\",\n",
    "                                         \"Hue\",\n",
    "                                         \"OD280/OD315 of diluted wines\",\n",
    "                                         \"Proline\"])\n",
    "\n",
    "\n",
    "wine.Class = wine.Class - 1\n",
    "\n",
    "# K-means from scratch \n",
    "X = wine.iloc[:, [12, 1]].values \n",
    "\n",
    "data = pd.DataFrame(X)\n",
    "\n",
    "val1 = data[0].values\n",
    "val2 = data[1].values\n",
    "\n",
    "#Euclidean Distance Function\n",
    "def dist(x, y, ax=1):\n",
    "    return np.linalg.norm(x - y, axis=ax)\n",
    "\n",
    "# Number of clusters\n",
    "k = 3\n",
    "\n",
    "# Creating random centroids\n",
    "# random x coordinates of centroids\n",
    "x_coor = np.random.randint(0, np.max(X)-7, size=k)\n",
    "# random y coordinates of random centroids\n",
    "y_coor = np.random.randint(0, np.max(X)-7, size=k)\n",
    "# Centroids\n",
    "_centroid = np.array(list(zip(x_coor, y_coor)), dtype=np.float32)\n",
    "print(\"Initial Centroids\")\n",
    "print(_centroid)\n",
    "\n",
    "# Plotting actual values and the random centroids\n",
    "plt.scatter(val1, val2, c='#050505', s=7)\n",
    "plt.scatter(x_coor, y_coor, marker='x', s=200, c='g')\n",
    "\n",
    "# To store the old value of centroids when it updates\n",
    "my_centroid = np.zeros(_centroid.shape)\n",
    "clusters = np.zeros(len(X))\n",
    "\n",
    "# Error function  - Distance between updated and old centroids\n",
    "error = dist(_centroid, my_centroid, None)\n",
    "\n",
    "# Loop will run till the error becomes zero\n",
    "while error != 0:\n",
    "    # Assigning each value to its closest cluster\n",
    "    for i in range(len(X)):\n",
    "        distances = dist(X[i], _centroid)\n",
    "        cluster = np.argmin(distances)\n",
    "        clusters[i] = cluster\n",
    "    # Storing the old centroid values\n",
    "    C_old = deepcopy(_centroid)\n",
    "    # Finding the new centroids by taking the average value\n",
    "    for i in range(k):\n",
    "        points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "        _centroid[i] = np.mean(points, axis=0)\n",
    "    error = dist(_centroid, my_centroid, None)\n",
    "\n",
    "colors = ['red','blue','green']\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(k):\n",
    "        points = np.array([X[j] for j in range(len(X)) if clusters[j] == i])\n",
    "        ax.scatter(points[:, 0], points[:, 1], s=7, c=colors[i])\n",
    "ax.scatter(_centroid[:, 0], _centroid[:, 1], marker='*', s=200, c='#050505')\n",
    "\n",
    "           \n",
    "# K means with scikit-learn libraries\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. K-means can go wrong!\n",
    "\n",
    "Since Clustering algorithms are for unsupervised data,chance of getting less optimal result is \n",
    "possible.One reason is differently from supervised learning, here we define k(number of clusters) \n",
    "as an input,it is not learned from data.In Random Initialization,the initial centroids is randomly\n",
    "chosen by k-means,which is randomly assigned to some points.In another kind of initialization, \n",
    "Forgy Method, the initial points chosen by dataset. Generally, Forgy method is more successful\n",
    "than Random Initialization. There is also k-means++ which is improved version for handling poor \n",
    "clustering. Considering properties of clustering such as number of clusters, cluster overlap, \n",
    "balance or unbalance, inilialization is important to get optimal result. In a poor cluster cost \n",
    "function(error between actual and predicted value) is high while in good cluster cost function is \n",
    "less(because of less error). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
